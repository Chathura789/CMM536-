{"cells":[{"cell_type":"markdown","metadata":{"id":"1SSCxZ_rnDMU"},"source":["# Topic 8 Lab"]},{"cell_type":"markdown","metadata":{"id":"LAByEdJgnDMZ"},"source":["Now that you know the basis of a CNN, you will run one of them in very few lines of code! To do so, we will use `Keras` with a `Tensorflow` backend, along with the very popular `mnist` dataset of handwritten numbers."]},{"cell_type":"markdown","metadata":{"id":"UfNlq1WknDMc"},"source":["First, install the necessary packages if you don't have them already:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9grvxB__nDMf","outputId":"1cecb7f7-02a4-47a3-d997-28419086870b","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.0)\n","Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.24.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n","Collecting tf-estimator-nightly==2.8.0.dev2021122109\n","  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n","\u001b[K     |████████████████████████████████| 462 kB 15.2 MB/s \n","\u001b[?25hRequirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.13.3)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.44.0)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (13.0.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.5)\n","Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n","Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.10.0.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.7.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n"]}],"source":["# 0. Installing the necesssary packages\n","!pip install keras\n","!pip install tensorflow"]},{"cell_type":"markdown","metadata":{"id":"-VUSmyOSnDMk"},"source":["Then we will ensure that `Keras` uses `Tensorflow` as backend. Notice that if you prefer to use another backend such as `Theano`, you simply need to change the name in the second line of the code."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dA00Jy9CnDMm"},"outputs":[],"source":["# 1. Ensure you are using Theano backend\n","import os\n","os.environ['KERAS_BACKEND'] = 'tensorflow'"]},{"cell_type":"markdown","metadata":{"id":"aqaLJp47nDMn"},"source":["Now you will import the necessary packages:"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"nkZUAk8NnDMo","executionInfo":{"status":"ok","timestamp":1647510430883,"user_tz":0,"elapsed":178,"user":{"displayName":"Chathura Perera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNkz3ZNLMUIfBhvSsLuSDHUh65m76xBuJQMijzWQ=s64","userId":"00302708811059304888"}}},"outputs":[],"source":["# 2. Import libraries and modules\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from keras.datasets import mnist\n","from keras.utils import np_utils"]},{"cell_type":"markdown","metadata":{"id":"vOcoU4RynDMq"},"source":["Then, we will set a **random seed** to be able to repeat the results and get the same results every time."]},{"cell_type":"code","execution_count":7,"metadata":{"id":"i0eUxbH6nDMr","executionInfo":{"status":"ok","timestamp":1647510432272,"user_tz":0,"elapsed":223,"user":{"displayName":"Chathura Perera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNkz3ZNLMUIfBhvSsLuSDHUh65m76xBuJQMijzWQ=s64","userId":"00302708811059304888"}}},"outputs":[],"source":["# 3. Set random seed (for reproducibility)\n","np.random.seed(123)"]},{"cell_type":"markdown","metadata":{"id":"q-xSJAVJnDMs"},"source":["With the following cell you will download the data from the `mnist` dataset. Notice that the data comes already partitioned in test and training sets:"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"04S0QwfnnDMt","executionInfo":{"status":"ok","timestamp":1647510433801,"user_tz":0,"elapsed":346,"user":{"displayName":"Chathura Perera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNkz3ZNLMUIfBhvSsLuSDHUh65m76xBuJQMijzWQ=s64","userId":"00302708811059304888"}},"outputId":"08963cd4-e5be-495d-f1cd-51331d738242","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","11501568/11490434 [==============================] - 0s 0us/step\n"]}],"source":["# 4. Load pre-shuffled MNIST data into train and test sets\n","(X_train, Y_train), (X_test, Y_test) = mnist.load_data()"]},{"cell_type":"markdown","metadata":{"id":"-9zkF8UMnDMu"},"source":["Let's check the shape of the things obtained:"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"CDm-Hn2YnDMv","executionInfo":{"status":"ok","timestamp":1647510436405,"user_tz":0,"elapsed":156,"user":{"displayName":"Chathura Perera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNkz3ZNLMUIfBhvSsLuSDHUh65m76xBuJQMijzWQ=s64","userId":"00302708811059304888"}},"outputId":"8134c9d9-fbde-4e1c-dd49-679370c339fe","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n"]}],"source":["print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)"]},{"cell_type":"markdown","metadata":{"id":"9OCbcXrwnDMw"},"source":["Notice that we have 60'000 samples for training and 10'000 for testing."]},{"cell_type":"markdown","metadata":{"id":"jBkxkbCmnDMw"},"source":["Now we will preprocess the data to be used by the classifier. To be able to use Keras, we need to do the following:\n","1. **Reshape** the data into **four** dimensions i.e. the training set will be of shape (60000,28,28,1) and the test set of (10000,28,28). This is useful since the network needs an input shape of (1,28,28) **for each of the samples**.\n","2. Convert the format of the input into `float32` (apparently the CNN works better with it).\n","3. **Normalise** i.e. divide all values by 255."]},{"cell_type":"code","execution_count":10,"metadata":{"id":"tj9YxpYfnDMx","executionInfo":{"status":"ok","timestamp":1647510438257,"user_tz":0,"elapsed":183,"user":{"displayName":"Chathura Perera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNkz3ZNLMUIfBhvSsLuSDHUh65m76xBuJQMijzWQ=s64","userId":"00302708811059304888"}}},"outputs":[],"source":["# 5. Preprocess input data\n","# Reshape into four dimensions.\n","X_train_reshape = X_train.reshape(X_train.shape[0], 28, 28, 1)\n","X_test_reshape = X_test.reshape(X_test.shape[0], 28, 28, 1)\n","# Convert to float 32\n","X_train_reshape = X_train_reshape.astype('float32')\n","X_test_reshape = X_test_reshape.astype('float32')\n","# normalise\n","X_train_reshape /= 255 \n","X_test_reshape /= 255"]},{"cell_type":"markdown","metadata":{"id":"cSOyV4UbnDM0"},"source":["CNNs also like their target to be categorical, i.e. instead of the target being values from 0 to 9, each target value will be a vector indicating which is the class according to the position. Run the following cell to see what I mean..."]},{"cell_type":"code","execution_count":11,"metadata":{"id":"v7QcNnlfnDM1","executionInfo":{"status":"ok","timestamp":1647510441436,"user_tz":0,"elapsed":476,"user":{"displayName":"Chathura Perera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNkz3ZNLMUIfBhvSsLuSDHUh65m76xBuJQMijzWQ=s64","userId":"00302708811059304888"}},"outputId":"1355603f-cd50-48b3-a4c7-695b13f237ea","colab":{"base_uri":"https://localhost:8080/","height":300}},"outputs":[{"output_type":"stream","name":"stdout","text":["[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"]},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7f1ed0123f50>"]},"metadata":{},"execution_count":11},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["# 6. Preprocess class labels\n","Y_train_categorical = np_utils.to_categorical(Y_train, 10)\n","Y_test_categorical = np_utils.to_categorical(Y_test, 10)\n","# Show a sample target entry. You will see that this sample corresponds to a 5 as\n","# there is a five in the 0th position (remember that python starts in 0)\n","print(Y_train_categorical[0])\n","plt.imshow(X_train[0])"]},{"cell_type":"markdown","metadata":{"id":"Bgx8rjqdnDM2"},"source":["Now it's time to train the model. We will define a **sequential** CNN with two convolutional layers, a **max pooling** of size $2 \\times 2$ and a **dropout** of $0.25$. Then, we will add a **flatten** layer, add a **densely connected** layer with a **ReLu** activation, afterwards add another **dropout** of $0.5$, and finally add a densely connected layer to the output with a **softmax** activation function. This configuration is not strict and you can find many different examples, such as [this other one](https://towardsdatascience.com/image-classification-in-10-minutes-with-mnist-dataset-54c35b77a38d)."]},{"cell_type":"code","execution_count":35,"metadata":{"id":"tYtZp2H6nDM3","executionInfo":{"status":"ok","timestamp":1647511207136,"user_tz":0,"elapsed":172,"user":{"displayName":"Chathura Perera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNkz3ZNLMUIfBhvSsLuSDHUh65m76xBuJQMijzWQ=s64","userId":"00302708811059304888"}}},"outputs":[],"source":["# 7. Define model architecture\n","from keras.models import Sequential\n","from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n","\n","model = Sequential()\n"," \n","model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28,28,1)))\n","model.add(Conv2D(32, (3, 3), activation='LeakyReLU'))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","model.add(Dropout(0.25))\n","model.add(Flatten())\n","model.add(Dense(128, activation='LeakyReLU'))\n","model.add(Dropout(0.5))\n","model.add(Dense(10, activation='softmax'))"]},{"cell_type":"markdown","source":["To be congruent with what we saw on the lecture, let's see the model summary. Notice that before the dropout layer we had 589k features! But afterwards only 1290 are used."],"metadata":{"id":"WcubYnCFSQS-"}},{"cell_type":"code","source":["# 8. Print a summary of the model\n","model.summary()"],"metadata":{"id":"CMn9aBgbSQpr","executionInfo":{"status":"ok","timestamp":1647511209264,"user_tz":0,"elapsed":10,"user":{"displayName":"Chathura Perera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNkz3ZNLMUIfBhvSsLuSDHUh65m76xBuJQMijzWQ=s64","userId":"00302708811059304888"}},"outputId":"9311a245-3000-4b9a-a83c-e1e339f813a7","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_4\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d_8 (Conv2D)           (None, 26, 26, 32)        320       \n","                                                                 \n"," conv2d_9 (Conv2D)           (None, 24, 24, 32)        9248      \n","                                                                 \n"," max_pooling2d_4 (MaxPooling  (None, 12, 12, 32)       0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_8 (Dropout)         (None, 12, 12, 32)        0         \n","                                                                 \n"," flatten_4 (Flatten)         (None, 4608)              0         \n","                                                                 \n"," dense_8 (Dense)             (None, 128)               589952    \n","                                                                 \n"," dropout_9 (Dropout)         (None, 128)               0         \n","                                                                 \n"," dense_9 (Dense)             (None, 10)                1290      \n","                                                                 \n","=================================================================\n","Total params: 600,810\n","Trainable params: 600,810\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"irGWXAn0nDM4"},"source":["After creating the model architecture, we will compile it. We will use the **ADAM** optimiser to improve the loss obtained by the **categorical cross entropy** method, and then we will request the model to obtain the accuracy"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"rPRq-xp8nDM5","executionInfo":{"status":"ok","timestamp":1647511211348,"user_tz":0,"elapsed":160,"user":{"displayName":"Chathura Perera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNkz3ZNLMUIfBhvSsLuSDHUh65m76xBuJQMijzWQ=s64","userId":"00302708811059304888"}}},"outputs":[],"source":["# 9. Compile model\n","model.compile(loss='categorical_crossentropy',\n","              optimizer='Nadam',\n","              metrics=['accuracy'])"]},{"cell_type":"markdown","metadata":{"id":"kVlqDQ1PnDM5"},"source":["Once compiled, we will fit this model using our training data. If your computer is slow, I recommend you **NOT** to use the entire training dataset. This can be done by reducing the number `n` to something smaller than 60'000. Also, you can reduce the number of **epochs**."]},{"cell_type":"code","execution_count":45,"metadata":{"id":"ta32g1OAnDM6","executionInfo":{"status":"ok","timestamp":1647511666842,"user_tz":0,"elapsed":142179,"user":{"displayName":"Chathura Perera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNkz3ZNLMUIfBhvSsLuSDHUh65m76xBuJQMijzWQ=s64","userId":"00302708811059304888"}},"outputId":"200c2f2c-b372-4f7e-caf8-a65fe282d88a","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","235/235 [==============================] - 5s 20ms/step - loss: 0.0144 - accuracy: 0.9952\n","Epoch 2/20\n","235/235 [==============================] - 5s 20ms/step - loss: 0.0131 - accuracy: 0.9957\n","Epoch 3/20\n","235/235 [==============================] - 5s 20ms/step - loss: 0.0117 - accuracy: 0.9963\n","Epoch 4/20\n","235/235 [==============================] - 5s 19ms/step - loss: 0.0109 - accuracy: 0.9964\n","Epoch 5/20\n","235/235 [==============================] - 5s 20ms/step - loss: 0.0113 - accuracy: 0.9961\n","Epoch 6/20\n","235/235 [==============================] - 5s 20ms/step - loss: 0.0103 - accuracy: 0.9966\n","Epoch 7/20\n","235/235 [==============================] - 5s 20ms/step - loss: 0.0106 - accuracy: 0.9965\n","Epoch 8/20\n","235/235 [==============================] - 5s 20ms/step - loss: 0.0106 - accuracy: 0.9962\n","Epoch 9/20\n","235/235 [==============================] - 5s 20ms/step - loss: 0.0104 - accuracy: 0.9965\n","Epoch 10/20\n","235/235 [==============================] - 5s 20ms/step - loss: 0.0118 - accuracy: 0.9959\n","Epoch 11/20\n","235/235 [==============================] - 5s 20ms/step - loss: 0.0106 - accuracy: 0.9965\n","Epoch 12/20\n","235/235 [==============================] - 5s 20ms/step - loss: 0.0102 - accuracy: 0.9966\n","Epoch 13/20\n","235/235 [==============================] - 5s 21ms/step - loss: 0.0095 - accuracy: 0.9965\n","Epoch 14/20\n","235/235 [==============================] - 5s 20ms/step - loss: 0.0087 - accuracy: 0.9969\n","Epoch 15/20\n","235/235 [==============================] - 5s 20ms/step - loss: 0.0099 - accuracy: 0.9967\n","Epoch 16/20\n","235/235 [==============================] - 5s 20ms/step - loss: 0.0096 - accuracy: 0.9967\n","Epoch 17/20\n","235/235 [==============================] - 5s 20ms/step - loss: 0.0098 - accuracy: 0.9963\n","Epoch 18/20\n","235/235 [==============================] - 5s 20ms/step - loss: 0.0105 - accuracy: 0.9963\n","Epoch 19/20\n","235/235 [==============================] - 5s 20ms/step - loss: 0.0083 - accuracy: 0.9971\n","Epoch 20/20\n","235/235 [==============================] - 5s 19ms/step - loss: 0.0085 - accuracy: 0.9970\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f1de7405610>"]},"metadata":{},"execution_count":45}],"source":["# 10. Fit model on training data\n","n=30000 # In google colab, don't worry if you use all the data!\n","\n","model.fit(X_train_reshape[:n], Y_train_categorical[:n], \n","          batch_size=256, epochs=20, verbose=1) # verbose = 1 lets you see the training log for each iteration, higher values just gives you a summary"]},{"cell_type":"markdown","metadata":{"id":"pBBg9ykGnDM8"},"source":["We can try to add more `n` and epochs to see how much `training accuracy` we are capable to achieve. Also, keep in mind that if the `loss` is not going down, then the model is not learning! "]},{"cell_type":"markdown","metadata":{"id":"LmtWTbg1nDM8"},"source":["Now we can evaluate your model in the `test` data. We can as well obtain the `loss` and the `accuracy` for this new, unseen data for the model."]},{"cell_type":"code","execution_count":46,"metadata":{"id":"qEFP8jRfnDM9","executionInfo":{"status":"ok","timestamp":1647511709580,"user_tz":0,"elapsed":1375,"user":{"displayName":"Chathura Perera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNkz3ZNLMUIfBhvSsLuSDHUh65m76xBuJQMijzWQ=s64","userId":"00302708811059304888"}},"outputId":"3fd0e680-9f0f-4abb-c2d6-8fe6b0330f38","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Loss:  0.04172112047672272 \n","Acc:  0.9901000261306763\n"]}],"source":["# 11. Evaluate model on test data\n","loss, accuracy = model.evaluate(X_test_reshape[:n], Y_test_categorical[:n], verbose=0)\n","print('Loss: ', loss,'\\nAcc: ', accuracy)"]},{"cell_type":"markdown","metadata":{"id":"IU40tKiqnDM9"},"source":["With the following cell you can print the labels that were predicted by the model. Notice that the classes are not categorical anymore!"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"Z4ThHn12nDM-","executionInfo":{"status":"ok","timestamp":1647511406455,"user_tz":0,"elapsed":959,"user":{"displayName":"Chathura Perera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNkz3ZNLMUIfBhvSsLuSDHUh65m76xBuJQMijzWQ=s64","userId":"00302708811059304888"}},"outputId":"ccb6056b-b5ee-4834-e0d9-390d44edc159","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["[7 2 1 ... 4 5 6]\n"]}],"source":["# 12. Check the labels that have been predicted\n","predict_x=model.predict(X_test[:n]) \n","classes_x=np.argmax(predict_x,axis=1)\n","print(classes_x)"]},{"cell_type":"markdown","metadata":{"id":"wkjLgh9ZnDM-"},"source":["The next cell has a brief code that will help you find the incorrect labels by comparing the labels obtained for the test samples with their ground truth."]},{"cell_type":"code","execution_count":41,"metadata":{"id":"f-C-VpWPnDM_","executionInfo":{"status":"ok","timestamp":1647511408171,"user_tz":0,"elapsed":2,"user":{"displayName":"Chathura Perera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNkz3ZNLMUIfBhvSsLuSDHUh65m76xBuJQMijzWQ=s64","userId":"00302708811059304888"}},"outputId":"71689d9d-1279-45db-def0-d53f9c924181","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Sample 8 was classified as 6 when it really was 5\n","Sample 40 was classified as 8 when it really was 1\n","Sample 115 was classified as 9 when it really was 4\n","Sample 149 was classified as 8 when it really was 2\n","Sample 175 was classified as 9 when it really was 7\n","Sample 211 was classified as 8 when it really was 5\n","Sample 321 was classified as 7 when it really was 2\n","Sample 340 was classified as 3 when it really was 5\n","Sample 449 was classified as 5 when it really was 3\n","Sample 497 was classified as 8 when it really was 4\n","Sample 583 was classified as 8 when it really was 2\n","Sample 613 was classified as 8 when it really was 2\n","Sample 619 was classified as 8 when it really was 1\n","Sample 659 was classified as 1 when it really was 2\n","Sample 684 was classified as 9 when it really was 7\n","Sample 689 was classified as 9 when it really was 7\n","Sample 696 was classified as 8 when it really was 1\n","Sample 717 was classified as 6 when it really was 0\n","Sample 720 was classified as 8 when it really was 5\n","Sample 726 was classified as 4 when it really was 7\n","Sample 738 was classified as 8 when it really was 2\n","Sample 813 was classified as 8 when it really was 9\n","Sample 842 was classified as 9 when it really was 7\n","Sample 846 was classified as 9 when it really was 7\n","Sample 939 was classified as 0 when it really was 2\n","Sample 994 was classified as 8 when it really was 1\n","Sample 1014 was classified as 8 when it really was 6\n","Sample 1039 was classified as 8 when it really was 7\n","Sample 1164 was classified as 9 when it really was 7\n","Sample 1182 was classified as 8 when it really was 6\n","Sample 1216 was classified as 9 when it really was 7\n","Sample 1226 was classified as 2 when it really was 7\n","Sample 1232 was classified as 4 when it really was 9\n","Sample 1242 was classified as 9 when it really was 4\n","Sample 1263 was classified as 9 when it really was 4\n","Sample 1319 was classified as 0 when it really was 8\n","Sample 1326 was classified as 2 when it really was 7\n","Sample 1393 was classified as 3 when it really was 5\n","Sample 1522 was classified as 9 when it really was 7\n","Sample 1621 was classified as 6 when it really was 0\n","Sample 1641 was classified as 6 when it really was 5\n","Sample 1709 was classified as 8 when it really was 9\n","Sample 1754 was classified as 2 when it really was 7\n","Sample 1773 was classified as 6 when it really was 1\n","Sample 1790 was classified as 7 when it really was 2\n","Sample 1809 was classified as 9 when it really was 7\n","Sample 1901 was classified as 8 when it really was 9\n","Sample 1911 was classified as 8 when it really was 5\n","Sample 2035 was classified as 3 when it really was 5\n","Sample 2040 was classified as 6 when it really was 5\n","Sample 2043 was classified as 8 when it really was 4\n","Sample 2053 was classified as 9 when it really was 4\n","Sample 2070 was classified as 9 when it really was 7\n","Sample 2118 was classified as 0 when it really was 6\n","Sample 2129 was classified as 8 when it really was 9\n","Sample 2130 was classified as 9 when it really was 4\n","Sample 2135 was classified as 8 when it really was 6\n","Sample 2185 was classified as 8 when it really was 0\n","Sample 2237 was classified as 8 when it really was 5\n","Sample 2266 was classified as 4 when it really was 1\n","Sample 2293 was classified as 0 when it really was 9\n","Sample 2369 was classified as 8 when it really was 5\n","Sample 2380 was classified as 0 when it really was 9\n","Sample 2406 was classified as 8 when it really was 9\n","Sample 2414 was classified as 8 when it really was 9\n","Sample 2462 was classified as 0 when it really was 2\n","Sample 2480 was classified as 9 when it really was 7\n","Sample 2573 was classified as 8 when it really was 5\n","Sample 2597 was classified as 3 when it really was 5\n","Sample 2654 was classified as 1 when it really was 6\n","Sample 2659 was classified as 8 when it really was 4\n","Sample 2743 was classified as 8 when it really was 5\n","Sample 2896 was classified as 0 when it really was 8\n","Sample 2930 was classified as 6 when it really was 5\n","Sample 2939 was classified as 5 when it really was 9\n","Sample 2995 was classified as 8 when it really was 6\n","Sample 3030 was classified as 0 when it really was 6\n","Sample 3073 was classified as 2 when it really was 1\n","Sample 3109 was classified as 9 when it really was 7\n","Sample 3213 was classified as 9 when it really was 7\n","Sample 3225 was classified as 8 when it really was 7\n","Sample 3330 was classified as 8 when it really was 2\n","Sample 3384 was classified as 6 when it really was 2\n","Sample 3414 was classified as 8 when it really was 5\n","Sample 3422 was classified as 0 when it really was 6\n","Sample 3441 was classified as 8 when it really was 7\n","Sample 3451 was classified as 9 when it really was 7\n","Sample 3520 was classified as 4 when it really was 6\n","Sample 3534 was classified as 8 when it really was 4\n","Sample 3558 was classified as 0 when it really was 5\n","Sample 3598 was classified as 8 when it really was 1\n","Sample 3601 was classified as 6 when it really was 1\n","Sample 3681 was classified as 8 when it really was 2\n","Sample 3718 was classified as 9 when it really was 4\n","Sample 3727 was classified as 9 when it really was 8\n","Sample 3730 was classified as 9 when it really was 7\n","Sample 3742 was classified as 9 when it really was 3\n","Sample 3751 was classified as 2 when it really was 7\n","Sample 3762 was classified as 8 when it really was 6\n","Sample 3776 was classified as 8 when it really was 5\n","Sample 3778 was classified as 8 when it really was 5\n","Sample 3796 was classified as 8 when it really was 2\n","Sample 3806 was classified as 8 when it really was 5\n","Sample 3808 was classified as 8 when it really was 7\n","Sample 3853 was classified as 8 when it really was 6\n","Sample 3893 was classified as 6 when it really was 5\n","Sample 3902 was classified as 3 when it really was 5\n","Sample 3906 was classified as 3 when it really was 1\n","Sample 4007 was classified as 9 when it really was 7\n","Sample 4017 was classified as 8 when it really was 4\n","Sample 4027 was classified as 4 when it really was 7\n","Sample 4078 was classified as 8 when it really was 9\n","Sample 4176 was classified as 8 when it really was 2\n","Sample 4199 was classified as 9 when it really was 7\n","Sample 4201 was classified as 7 when it really was 1\n","Sample 4238 was classified as 3 when it really was 7\n","Sample 4248 was classified as 8 when it really was 2\n","Sample 4256 was classified as 2 when it really was 3\n","Sample 4308 was classified as 8 when it really was 1\n","Sample 4330 was classified as 8 when it really was 5\n","Sample 4498 was classified as 8 when it really was 7\n","Sample 4507 was classified as 3 when it really was 1\n","Sample 4548 was classified as 6 when it really was 5\n","Sample 4551 was classified as 4 when it really was 7\n","Sample 4571 was classified as 8 when it really was 6\n","Sample 4578 was classified as 9 when it really was 7\n","Sample 4615 was classified as 4 when it really was 2\n","Sample 4740 was classified as 5 when it really was 3\n","Sample 4761 was classified as 8 when it really was 9\n","Sample 4771 was classified as 8 when it really was 5\n","Sample 4815 was classified as 9 when it really was 7\n","Sample 4823 was classified as 4 when it really was 9\n","Sample 4864 was classified as 8 when it really was 1\n","Sample 4888 was classified as 8 when it really was 5\n","Sample 4921 was classified as 9 when it really was 7\n","Sample 4966 was classified as 8 when it really was 7\n","Sample 5246 was classified as 2 when it really was 7\n","Sample 5634 was classified as 8 when it really was 2\n","Sample 5654 was classified as 2 when it really was 7\n","Sample 5752 was classified as 3 when it really was 5\n","Sample 5887 was classified as 0 when it really was 7\n","Sample 5888 was classified as 0 when it really was 4\n","Sample 5955 was classified as 8 when it really was 3\n","Sample 5997 was classified as 9 when it really was 5\n","Sample 6091 was classified as 5 when it really was 9\n","Sample 6166 was classified as 3 when it really was 9\n","Sample 6172 was classified as 5 when it really was 9\n","Sample 6173 was classified as 0 when it really was 9\n","Sample 6505 was classified as 0 when it really was 9\n","Sample 6561 was classified as 9 when it really was 7\n","Sample 6576 was classified as 1 when it really was 7\n","Sample 6597 was classified as 9 when it really was 0\n","Sample 6651 was classified as 8 when it really was 0\n","Sample 6744 was classified as 8 when it really was 2\n","Sample 6783 was classified as 6 when it really was 1\n","Sample 6981 was classified as 3 when it really was 5\n","Sample 7240 was classified as 3 when it really was 5\n","Sample 7434 was classified as 8 when it really was 4\n","Sample 7451 was classified as 3 when it really was 5\n","Sample 7842 was classified as 8 when it really was 5\n","Sample 7902 was classified as 9 when it really was 7\n","Sample 7915 was classified as 8 when it really was 7\n","Sample 8094 was classified as 8 when it really was 2\n","Sample 8128 was classified as 6 when it really was 1\n","Sample 8316 was classified as 2 when it really was 7\n","Sample 8527 was classified as 9 when it really was 4\n","Sample 9009 was classified as 2 when it really was 7\n","Sample 9015 was classified as 2 when it really was 7\n","Sample 9016 was classified as 8 when it really was 0\n","Sample 9019 was classified as 2 when it really was 7\n","Sample 9024 was classified as 2 when it really was 7\n","Sample 9530 was classified as 8 when it really was 9\n","Sample 9540 was classified as 8 when it really was 1\n","Sample 9637 was classified as 9 when it really was 7\n","Sample 9679 was classified as 3 when it really was 6\n","Sample 9729 was classified as 6 when it really was 5\n","Sample 9754 was classified as 6 when it really was 5\n","Sample 9770 was classified as 0 when it really was 5\n","Sample 9811 was classified as 8 when it really was 2\n","Sample 9839 was classified as 3 when it really was 2\n","Sample 9850 was classified as 8 when it really was 0\n","Sample 9879 was classified as 2 when it really was 0\n","Sample 9904 was classified as 8 when it really was 2\n","Sample 9941 was classified as 8 when it really was 5\n","Sample 9982 was classified as 6 when it really was 5\n"]}],"source":["# 13. Check the label that has been predicted incorrectly\n","incorrect_labels=[]\n","accuracy = 0\n","for i,cla in enumerate(classes_x):\n","  if cla != Y_test[:n][i]:\n","    print(\"Sample \"+str(i)+\" was classified as \"+str(cla)+\" when it really was \"+str(Y_test[:n][i]))"]},{"cell_type":"markdown","metadata":{"id":"z1oAQn11nDNA"},"source":["Finally, you can use the following cell to print training or test cells from the dataset and see their actual (and predicted, for the case of test) labels."]},{"cell_type":"code","execution_count":44,"metadata":{"id":"78oido3SnDNA","executionInfo":{"status":"ok","timestamp":1647511427375,"user_tz":0,"elapsed":520,"user":{"displayName":"Chathura Perera","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhNkz3ZNLMUIfBhvSsLuSDHUh65m76xBuJQMijzWQ=s64","userId":"00302708811059304888"}},"outputId":"f31c9d13-3c5f-4c96-c02e-705021dc6631","colab":{"base_uri":"https://localhost:8080/","height":300}},"outputs":[{"output_type":"stream","name":"stdout","text":["Ground truth label:  1\n","Predicted label:  1\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["# 14. Show a sample from the mnist dataset\n","image_to_show = 900\n","from_group = 'test' # 'train' or 'test'\n","if from_group == 'train':\n","    plt.imshow(X_train[image_to_show])\n","    print('Ground truth label: ',Y_train[image_to_show])\n","else:\n","    plt.imshow(X_test[image_to_show])\n","    print('Ground truth label: ',Y_test[image_to_show])\n","    if len(predict_x)>image_to_show:\n","        print('Predicted label: ',classes_x[image_to_show])"]}],"metadata":{"hide_input":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false},"colab":{"name":"Copy of CMM536_T8_Lab.ipynb","provenance":[{"file_id":"1LYfBcMVdClHKGqxkO_Q_rstTPEbaoguX","timestamp":1647509300185}],"collapsed_sections":[]},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}